{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc41133-843f-4aa9-940d-c114f0e508db",
   "metadata": {},
   "source": [
    "## Install and import depdencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec18d81f-c8ae-4641-8927-98a6a6fb1e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - pytorch\n",
      " - nvidia\n",
      " - defaults\n",
      " - anaconda\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d75ad27-67c4-4bb3-9373-2fa73a99cd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (8.2.28)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (4.10.0.82)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (0.18.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=0.2.5 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from ultralytics) (0.2.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\msi\\.conda\\envs\\reciept-scanner\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da25ee3-8d68-4dd6-9355-327a362f12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c6402-5715-4b85-9742-2f0b631a508b",
   "metadata": {},
   "source": [
    "## Prep training materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe251a3a-4ba7-4199-9567-daa167dec175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa9ac0-c67e-4375-8da4-d2c8888de5d7",
   "metadata": {},
   "source": [
    "Please make sure all images are labeled using YOLO format.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Create a folder named \"data\" OUTSIDE of the local repo. This folder will contain all your data.\n",
    "2. Create a subdirectory inside the data folder and add one folder named \"unsplit\". Add your images and labels folders to this subdirectory.\n",
    "   I have included an exmaple directory inside the RSYOLOV8 folder. This is how your data folder should be set up before running the next part of the code.\n",
    "3. Please go into the config.yaml file and set the \"path\" variable to the ABSOLUTE PATH of the data folder.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b426527-49c4-4e15-ac05-c7e329223644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the data folder below as well.\n",
    "data_dir = \"D:/RecieptScanner\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50af167-bb66-439e-93bd-06c575458876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "unsplit_dir = os.path.join(data_dir, 'unsplit')\n",
    "images_dir = os.path.join(unsplit_dir, 'images')\n",
    "labels_dir = os.path.join(unsplit_dir, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdbdb47-78fa-40e4-8bac-909e2b4ebd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New directories\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc083c0-0e93-4fcc-8f19-3f4f0dc66680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directories\n",
    "for split_dir in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(os.path.join(split_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(split_dir, 'labels'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1896c969-27ac-4c64-84e1-a7c97dfa4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbd444d-bcfe-4f76-9b12-e4c17284d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unsplit images and labels\n",
    "images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "labels = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5189b19-9598-41ef-afac-81f34290e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there is a label for each image\n",
    "images = [img for img in images if f'{os.path.splitext(img)[0]}.txt' in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a95dba9-762d-42ad-9e19-057bce2198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392fbe9c-f5ef-4a94-96b9-375e82ca6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate split sizes\n",
    "total_images = len(images)\n",
    "train_size = int(total_images * train_ratio)\n",
    "val_size = int(total_images * val_ratio)\n",
    "test_size = total_images - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7bc638f-6bda-4041-8932-235cd5a9f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images and labels\n",
    "train_images = images[:train_size]\n",
    "val_images = images[train_size:train_size + val_size]\n",
    "test_images = images[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a86478-75d7-4726-951e-e814d3d00844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move files to appropriate directories\n",
    "def move_files(file_list, source_img_dir, source_lbl_dir, target_dir):\n",
    "    for file_name in file_list:\n",
    "        img_source_path = os.path.join(source_img_dir, file_name)\n",
    "        lbl_source_path = os.path.join(source_lbl_dir, f'{os.path.splitext(file_name)[0]}.txt')\n",
    "        \n",
    "        img_target_path = os.path.join(target_dir, 'images', file_name)\n",
    "        lbl_target_path = os.path.join(target_dir, 'labels', f'{os.path.splitext(file_name)[0]}.txt')\n",
    "        \n",
    "        shutil.copy(img_source_path, img_target_path)\n",
    "        shutil.copy(lbl_source_path, lbl_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02b936da-ebdc-492d-962c-ad96838b1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files to train, val, test directories\n",
    "move_files(train_images, images_dir, labels_dir, train_dir)\n",
    "move_files(val_images, images_dir, labels_dir, val_dir)\n",
    "move_files(test_images, images_dir, labels_dir, test_dir)\n",
    "\n",
    "# You are now ready to train!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3e9a4-fa6b-4a34-a069-c67f8fcebddc",
   "metadata": {},
   "source": [
    "## Select model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927ab775-88e5-468e-b668-70fa1d712351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')  # or 'yolov8s.pt' for pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c1440-3a4e-413e-8841-82d1c0c72a82",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2430c5-dff0-45e6-9613-95b49cfa61c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.31 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.28  Python-3.11.9 torch-2.3.1 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=config.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\RecieptScanner\\data\\train\\labels.cache... 4 images, 0 backgrounds, 4 corrupt: 100%|██████████| 4/4 [\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RecieptScanner\\data\\train\\images\\20240610_203804_jpg.rf.1ec8731b64504cad2e8ddbdd01fabbe6.jpg: ignoring corrupt image/label: Label class 2 exceeds dataset class count 1. Possible class labels are 0-0\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RecieptScanner\\data\\train\\images\\20240610_203852_jpg.rf.ff74bbc1ce891c59e9cc53d4d21ac4e7.jpg: ignoring corrupt image/label: Label class 2 exceeds dataset class count 1. Possible class labels are 0-0\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RecieptScanner\\data\\train\\images\\20240610_203914_jpg.rf.db5d260376b2be4a0159f50b32796d88.jpg: ignoring corrupt image/label: Label class 2 exceeds dataset class count 1. Possible class labels are 0-0\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  D:\\RecieptScanner\\data\\train\\images\\20240610_203948_jpg.rf.ffb53f295436ee5187a1fad10f8d5f79.jpg: ignoring corrupt image/label: Label class 2 exceeds dataset class count 1. Possible class labels are 0-0\n",
      "WARNING  No images found in D:\\RecieptScanner\\data\\train\\labels.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# data: Specifies the path to the dataset configuration file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# imgsz: Sets the image size\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# batch: Sets the batch size\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# epochs: Sets the number of epochs\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# workers: Sets the number of data loader workers ( i have no idea what this does )\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\engine\\model.py:674\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:199\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:313\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[1;32m--> 313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_train(world_size)\n\u001b[0;32m    315\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[0;32m    316\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:277\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[0;32m    276\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(world_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, rank\u001b[38;5;241m=\u001b[39mRANK, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:49\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[1;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[38;5;66;03m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_dataset(dataset_path, mode, batch_size)\n\u001b[0;32m     50\u001b[0m shuffle \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m shuffle:\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:43\u001b[0m, in \u001b[0;36mDetectionTrainer.build_dataset\u001b[1;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mBuild YOLO Dataset.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    batch (int, optional): Size of batches, this is for `rect`. Defaults to None.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(de_parallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m build_yolo_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, img_path, batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, mode\u001b[38;5;241m=\u001b[39mmode, rect\u001b[38;5;241m=\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, stride\u001b[38;5;241m=\u001b[39mgs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\data\\build.py:87\u001b[0m, in \u001b[0;36mbuild_yolo_dataset\u001b[1;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build YOLO Dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m dataset \u001b[38;5;241m=\u001b[39m YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset(\n\u001b[0;32m     88\u001b[0m     img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[0;32m     89\u001b[0m     imgsz\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mimgsz,\n\u001b[0;32m     90\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m     91\u001b[0m     augment\u001b[38;5;241m=\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# augmentation\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     hyp\u001b[38;5;241m=\u001b[39mcfg,  \u001b[38;5;66;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     rect\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mrect \u001b[38;5;129;01mor\u001b[39;00m rect,  \u001b[38;5;66;03m# rectangular batches\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     cache\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     95\u001b[0m     single_cls\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39msingle_cls \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m     stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(stride),\n\u001b[0;32m     97\u001b[0m     pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     98\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mcolorstr(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     99\u001b[0m     task\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtask,\n\u001b[0;32m    100\u001b[0m     classes\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mclasses,\n\u001b[0;32m    101\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    102\u001b[0m     fraction\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mfraction \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    103\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\data\\dataset.py:64\u001b[0m, in \u001b[0;36mYOLODataset.__init__\u001b[1;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_keypoints), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not use both segments and keypoints.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\data\\base.py:74\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[1;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfraction \u001b[38;5;241m=\u001b[39m fraction\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_img_files(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_labels()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_labels(include_class\u001b[38;5;241m=\u001b[39mclasses)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mni \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)  \u001b[38;5;66;03m# number of images\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\reciept-scanner\\Lib\\site-packages\\ultralytics\\data\\dataset.py:161\u001b[0m, in \u001b[0;36mYOLODataset.get_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Check if the dataset is all boxes or all segments\u001b[39;00m\n\u001b[0;32m    160\u001b[0m lengths \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28mlen\u001b[39m(lb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(lb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(lb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m lb \u001b[38;5;129;01min\u001b[39;00m labels)\n\u001b[1;32m--> 161\u001b[0m len_cls, len_boxes, len_segments \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mlengths))\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_segments \u001b[38;5;129;01mand\u001b[39;00m len_boxes \u001b[38;5;241m!=\u001b[39m len_segments:\n\u001b[0;32m    163\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlen_segments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen(boxes) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlen_boxes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. To resolve this only boxes will be used and all segments will be removed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    167\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "# data: Specifies the path to the dataset configuration file\n",
    "# imgsz: Sets the image size\n",
    "# batch: Sets the batch size\n",
    "# epochs: Sets the number of epochs\n",
    "# workers: Sets the number of data loader workers ( i have no idea what this does )\n",
    "model.train(data='config.yaml', imgsz=640, epochs=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2b027-0303-4908-b073-dd726eab49e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOv8",
   "language": "python",
   "name": "yolov8env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
