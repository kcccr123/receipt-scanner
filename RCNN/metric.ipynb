{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import typing \n","\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as op\n","from itertools import groupby"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#accrucacy metrics\n","def LEDist (pred: typing.List[str], truth: typing.List[str]) -> int:\n","    #Levenshtein distance Algorithm that measure the number of edits\n","    #needed to change prediction sentence to match ground truth\n","    matrix = [[0 for _ in range(len(truth) + 1)] for _ in range(len(pred) + 1)]\n","\n","    for i in range(len(pred)+1):\n","        matrix[i][0] = i\n","\n","    for j in range(len(truth)+1):\n","        matrix[0][j] = j\n","\n","    for i, p in enumerate(pred):\n","        for j, t in enumerate(truth):\n","            \n","            if p == t:\n","                matrix[i+1][j+1] = matrix[i][j]\n","                #number of operations needed is the same with or without this\n","                #char, so take the operations needed in the prev substring\n","            else:\n","                #min number of operations in prev substrings plus operation to this char\n","                matrix[i+1][j+1] = min(matrix[i][j+1], matrix[i+1][j+1], matrix[i][j])+1\n","    return matrix[-1][-1]\n","\n","def charError(pred: typing.Union[str, typing.List[str]], \n","              truth: typing.Union[str, typing.List[str]]) -> float:\n","    \n","    if isinstance(pred, str):\n","        pred = [pred]\n","    if isinstance(truth, str):\n","        truth = [truth]\n","\n","    totalChar, error = 0, 0\n","\n","    for p_words, t_words in zip(pred, truth):\n","        error += LEDist(p_words, t_words)\n","        totalChar += len(t_words)\n","    \n","    if totalChar != 0:\n","        cer = error/totalChar\n","        return cer\n","    else:\n","        return 0\n","\n","def wordError(pred: typing.Union[str, typing.List[str]], \n","              truth: typing.Union[str, typing.List[str]]) -> float:\n","    \n","    if isinstance(pred, str) and isinstance(truth, str):\n","        pred = [pred]\n","        truth = [truth]\n","\n","    if isinstance(pred, list) and isinstance(truth, list):\n","        totalWord, error = 0, 0\n","        for p_words, t_words in zip(pred, truth):\n","            if isinstance(p_words, str) and isinstance(t_words, str):\n","                error += LEDist(p_words.split(), t_words.split())\n","                totalWord += len(t_words.split())\n","            else:\n","                print(\"Error: preds and target must be either both strings or both lists of strings.\")\n","                return np.inf\n","    else:\n","        print(\"Error: preds and target must be either both strings or both lists of strings.\")\n","        return np.inf\n","    \n","    wer = error/totalWord\n","    return wer\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#metric base class\n","class Metric:\n","    def __init__(self, name: str) -> None:\n","        self.name = name\n","\n","    def reset(self):\n","        #Reset to initial values and return metric value\n","        self.__init__()\n","\n","    def update(self, pred: torch.Tensor, truth: torch.Tensor, **kwargs):\n","        pass\n","\n","    def result(self):\n","        pass\n","\n","\n","class Accuracy(Metric):\n","\n","    def __init__(self, name=\"accuracy\") -> None:\n","        super(Accuracy, self).__init__(name=name)\n","        self.correct = 0\n","        self.total = 0\n","\n","    def update(self, pred: torch.Tensor, truth: torch.Tensor, **kwargs):\n","\n","        _, predicted = torch.max(pred.data, 1)\n","        self.total += truth.size(0)\n","        self.correct += (predicted == truth).sum().item()\n","\n","    def result(self):\n","        return self.correct / self.total\n","\n","\n","class CERMetric(Metric):\n","\n","    def __init__(self, vocabulary: typing.Union[str, list], name: str = \"CER\") -> None:\n","        super(CERMetric, self).__init__(name=name)\n","        self.vocabulary = vocabulary #string of the vocabulary used to encode the labels.\n","        self.reset()\n","\n","    def reset(self):\n","        self.cer = 0\n","        self.counter = 0\n","\n","    def update(self, pred: torch.Tensor, truth: torch.Tensor, **kwargs) -> None:\n","        # convert to numpy\n","        pred = pred.detach().cpu().numpy()\n","        truth = truth.detach().cpu().numpy()\n","\n","        # index of the highest probability\n","        argmax_preds = np.argmax(pred, axis=-1)\n","        \n","        # group same indexes\n","        grouped_preds = [[k for k,_ in groupby(preds)] for preds in argmax_preds]\n","\n","        # convert indexes to strings\n","        output_texts = [\"\".join([self.vocabulary[k] for k in group if k < len(self.vocabulary)]) for group in grouped_preds]\n","        target_texts = [\"\".join([self.vocabulary[k] for k in group if k < len(self.vocabulary)]) for group in truth]\n","\n","        cer = charError(output_texts, target_texts)\n","\n","        self.cer += cer\n","        self.counter += 1\n","\n","    def result(self) -> float:\n","        return self.cer / self.counter\n","    \n","\n","class WERMetric(Metric):\n","\n","    def __init__(self, vocabulary: typing.Union[str, list], name: str = \"WER\") -> None:\n","        super(WERMetric, self).__init__(name=name)\n","        self.vocabulary = vocabulary\n","        self.reset()\n","\n","    def reset(self):\n","        self.wer = 0\n","        self.counter = 0\n","\n","    def update(self, pred: torch.Tensor, truth: torch.Tensor, **kwargs) -> None:\n","\n","        pred = pred.detach().cpu().numpy()\n","        truth = truth.detach().cpu().numpy()\n","\n","        argmax_preds = np.argmax(pred, axis=-1)\n","        \n","        grouped_preds = [[k for k,_ in groupby(preds)] for preds in argmax_preds]\n","\n","        output_texts = [\"\".join([self.vocabulary[k] for k in group if k < len(self.vocabulary)]) for group in grouped_preds]\n","        target_texts = [\"\".join([self.vocabulary[k] for k in group if k < len(self.vocabulary)]) for group in truth]\n","\n","        wer = wordError(output_texts, target_texts)\n","\n","        self.wer += wer\n","        self.counter += 1\n","\n","    def result(self) -> float:\n","        return self.wer / self.counter"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class Trainer:\n","    #class to train and test models\n","    def __init__(self, model: torch.nn.Module, optimizer: torch.optim.Optimizer, \n","                 loss: typing.Callable, metrics: typing.List[Metric] = []):\n","        return 0"]}],"metadata":{"kernelspec":{"display_name":"scannerTxtRead","language":"python","name":"scannertxtread"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":2}
