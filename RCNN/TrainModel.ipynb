{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import callbacks\n",
    "import data\n",
    "import dataUtils as du\n",
    "import image\n",
    "import metric\n",
    "import modelArc\n",
    "import trainer\n",
    "import json as js\n",
    "from config import ConfigFile\n",
    "from datetime import datetime\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mltu.torch.dataProvider import DataProvider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image with index 187 do not exist\n",
      "image with index 190 do not exist\n",
      "image with index 194 do not exist\n",
      "image with index 197 do not exist\n",
      "image with index 199 do not exist\n",
      "image with index 354 do not exist\n",
      "image with index 366 do not exist\n",
      "image with index 370 do not exist\n",
      "image with index 372 do not exist\n",
      "image with index 381 do not exist\n",
      "image with index 393 do not exist\n",
      "dataset1 done\n",
      "dataset2 done\n",
      "dataset3 done\n",
      "52433\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "#Specify path to main database\n",
    "data_dir = r\"D:\\photos\\RCNN4\\BBOXES\"\n",
    "model_path = r\"D:\\Projects\\reciept-scanner\\RCNN\\models\"\n",
    "database, vocab, max_len = [], set(), 0\n",
    "\n",
    "largest_index = 492\n",
    "\n",
    "for id in range(0, largest_index+1):\n",
    "\n",
    "    img_path = os.path.join(data_dir, str(id) + \".jpg\").replace(\"\\\\\",\"/\")\n",
    "    \n",
    "    if os.path.exists(img_path):\n",
    "        \n",
    "        with open(os.path.join(data_dir, str(id) + \".txt\").replace(\"\\\\\",\"/\"), 'r') as file:\n",
    "            ground_truths = [line.strip() for line in file.readlines()]\n",
    "        \n",
    "        for line in ground_truths:\n",
    "            if not line.strip() == '':\n",
    "                label = line.rstrip(\"\\n\")\n",
    "                database.append([img_path, label])\n",
    "                vocab.update(list(label))\n",
    "                max_len = max(max_len, len(label))\n",
    "    else:\n",
    "        print(\"image with index \" + str(id) + \" do not exist\")\n",
    "\n",
    "print(\"dataset1 done\")\n",
    "\n",
    "#load second dataset\n",
    "data_path = r\"D:\\photos\\SORIE\"\n",
    "\n",
    "path = os.path.join(data_path, \"train\").replace(\"\\\\\",\"/\")\n",
    "i = 1\n",
    "while i <= 2:\n",
    "    with open(os.path.join(path, \"metadata.jsonl\").replace(\"\\\\\",\"/\"), 'r') as file:\n",
    "        for line in file:\n",
    "            \n",
    "            row = js.loads(line)\n",
    "            img_path = os.path.join(path, row.get(\"file_name\")).replace(\"\\\\\",\"/\")\n",
    "            if os.path.exists(img_path):\n",
    "                label = row.get(\"text\").rstrip(\"\\n\")\n",
    "                vocab.update(list(label))\n",
    "                max_len = max(max_len, len(label))\n",
    "                database.append([img_path, label])\n",
    "            else:\n",
    "                print(\"image with path \" + str(img_path) + \" do not exist\")\n",
    "    if i == 1:\n",
    "        print(\"dataset2 done\")\n",
    "    \n",
    "    i += 1\n",
    "    path = os.path.join(data_path, \"test\").replace(\"\\\\\",\"/\")\n",
    "\n",
    "print(\"dataset3 done\")\n",
    "print(len(database))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels: 647645336\n",
      "Mean: [200.22298 196.8244  193.20657]\n",
      "Standard Deviation: [74.73709  75.59093  76.772415]\n",
      "normalization done\n"
     ]
    }
   ],
   "source": [
    "#normalize images and load them as an np array\n",
    "\n",
    "#get the mean and std of dataset\n",
    "num_pixels = 0\n",
    "channel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
    "channel_sum_squared = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "for pair in database:\n",
    "    image_path = pair[0]\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read image at {image_path}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pair[0] = img\n",
    "\n",
    "    height, width, num_channels = img.shape\n",
    "\n",
    "    num_pixels += height * width\n",
    "\n",
    "    channel_sum += torch.tensor(img.sum(axis=(0, 1)), dtype=torch.float64)\n",
    "    channel_sum_squared += torch.tensor((img.astype(np.float64) ** 2).sum(axis=(0, 1)), dtype=torch.float64)\n",
    "\n",
    "mean = channel_sum/num_pixels\n",
    "variance = (channel_sum_squared / num_pixels) - (mean**2)\n",
    "std = torch.sqrt(variance)\n",
    "print(\"Number of pixels:\", num_pixels)\n",
    "print(\"Mean:\", mean.numpy())\n",
    "print(\"Standard Deviation:\", std.numpy())\n",
    "\n",
    "for pair in database:\n",
    "    img_tensor = torch.tensor(pair[0], dtype=torch.float64) / 255.0\n",
    "\n",
    "    norm_img = (img_tensor - mean) / std\n",
    "    pair[0] = norm_img.numpy()\n",
    "\n",
    "print(\"normalization done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config saved toD:/Projects/reciept-scanner/RCNN/models/202407151638\n",
      "splitting data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m dataset_loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(dataset \u001b[38;5;241m=\u001b[39m database, batch_size \u001b[38;5;241m=\u001b[39m model_config\u001b[38;5;241m.\u001b[39mbatch_size, \n\u001b[0;32m      9\u001b[0m                                  data_preprocessors \u001b[38;5;241m=\u001b[39m [image\u001b[38;5;241m.\u001b[39mImageReader(image\u001b[38;5;241m.\u001b[39mCVImage)], \n\u001b[0;32m     10\u001b[0m                                  transformers \u001b[38;5;241m=\u001b[39m [du\u001b[38;5;241m.\u001b[39mImageResizer(model_config\u001b[38;5;241m.\u001b[39mwidth, model_config\u001b[38;5;241m.\u001b[39mheight), du\u001b[38;5;241m.\u001b[39mLabelIndexer(model_config\u001b[38;5;241m.\u001b[39mvocab), \n\u001b[0;32m     11\u001b[0m                                                  du\u001b[38;5;241m.\u001b[39mLabelPadding(padding_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(model_config\u001b[38;5;241m.\u001b[39mvocab), max_word_len \u001b[38;5;241m=\u001b[39m max_len)])\u001b[38;5;66;03m#, du.ImageShowCV2()\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplitting data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m train_set, val_set \u001b[38;5;241m=\u001b[39m dataset_loader\u001b[38;5;241m.\u001b[39msplit(split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplitting done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m train_set\u001b[38;5;241m.\u001b[39maugmentors \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m     du\u001b[38;5;241m.\u001b[39mRandomBrightness(),\n\u001b[0;32m     18\u001b[0m     du\u001b[38;5;241m.\u001b[39mRandomErodeDilate(),\n\u001b[0;32m     19\u001b[0m     du\u001b[38;5;241m.\u001b[39mRandomSharpen(),\n\u001b[0;32m     20\u001b[0m     du\u001b[38;5;241m.\u001b[39mRandomRotate(angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m     21\u001b[0m     ]\n",
      "File \u001b[1;32md:\\Projects\\reciept-scanner\\RCNN\\data.py:95\u001b[0m, in \u001b[0;36mDataLoader.split\u001b[1;34m(self, split, shuffle)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m     93\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[1;32m---> 95\u001b[0m train_data_loader, val_data_loader \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m), copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m     96\u001b[0m train_data_loader\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset[:\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset) \u001b[38;5;241m*\u001b[39m split)]\n\u001b[0;32m     97\u001b[0m val_data_loader\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset[\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset) \u001b[38;5;241m*\u001b[39m split):]\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\Gary Guo\\anaconda3\\envs\\scannerCRNN\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create data loaders\n",
    "model_config = ConfigFile(name = \"CRNN1\", path = model_path, lr=0.0022, bs=64)\n",
    "\n",
    "model_config.vocab = \"\".join(vocab)\n",
    "model_config.max_txt_len = max_len\n",
    "model_config.save()\n",
    "\n",
    "dataset_loader = data.DataLoader(dataset = database, batch_size = model_config.batch_size, \n",
    "                                 data_preprocessors = [image.ImageReader(image.CVImage)], \n",
    "                                 transformers = [du.ImageResizer(model_config.width, model_config.height), du.LabelIndexer(model_config.vocab), \n",
    "                                                 du.LabelPadding(padding_value = len(model_config.vocab), max_word_len = max_len)])#, du.ImageShowCV2()\n",
    "\n",
    "print(\"splitting data\")\n",
    "train_set, val_set = dataset_loader.split(split = 0.8)\n",
    "print(\"splitting done\")\n",
    "train_set.augmentors = [\n",
    "    du.RandomBrightness(),\n",
    "    du.RandomErodeDilate(),\n",
    "    du.RandomSharpen(),\n",
    "    du.RandomRotate(angle=10),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize model, optimizer, and loss\n",
    "model = modelArc.CRNN(len(model_config.vocab))\n",
    "loss = trainer.CTCLoss(blank = len(model_config.vocab))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_config.lr)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"CUDA Enabled...Training On GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialze callbacks and trainer\n",
    "earlystop = callbacks.EarlyStopping(monitor = \"val_CER\", patience = 10, verbose = True)\n",
    "ckpt = callbacks.ModelCheckpoint((model_config.model_path + \"/model.pt\").replace(\"\\\\\",\"/\"), monitor = \"val_CER\", verbose = True)\n",
    "tracker = callbacks.TensorBoard((model_config.model_path + \"/logs\").replace(\"\\\\\",\"/\"))\n",
    "auto_lr = callbacks.ReduceLROnPlateau(monitor = \"val_CER\", factor=0.9, patience = 10, verbose = True)\n",
    "save_model = callbacks.Model2onnx(saved_model_path = (os.path.join(model_path, datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"),\"model.pt\").replace(\"\\\\\",\"/\")), input_shape = (1, model_config.height, model_config.width, 3), verbose = True, metadata = {\"vocab\": model_config.vocab})\n",
    "\n",
    "\n",
    "train_struct = trainer.Trainer(model, optimizer, loss, metrics = [metric.CERMetric(model_config.vocab), metric.WERMetric(model_config.vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "train_struct.run(train_set, val_set, epochs=4, callbacks = [ckpt, tracker, auto_lr, save_model])#earlystop,\n",
    "\n",
    "train_set.to_csv(os.path.join(model_config.model_path, \"train.csv\").replace(\"\\\\\",\"/\"))\n",
    "val_set.to_csv(os.path.join(model_config.model_path, \"val.csv\").replace(\"\\\\\",\"/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scannerCRNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
